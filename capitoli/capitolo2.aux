\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{kasneci2023chatgpt}
\citation{yao2024survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Large Language Models (LLMs)}{11}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduzione e caratteristiche degli LLMs}{11}{section.2.1}\protected@file@percent }
\citation{achiam2023gpt}
\citation{liang2022holistic}
\citation{liang2022holistic}
\citation{liang2022holistic}
\citation{devlin2018bert}
\citation{raffel2020exploring}
\citation{narang2022pathways}
\citation{meta2023introducing}
\citation{keskar2019ctrl}
\citation{yao2024survey}
\citation{yao2024survey}
\citation{floridi2020gpt}
\citation{achiam2023gpt}
\citation{henighan2020scaling}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Esempi di LLMs attuali}{12}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Panoramica dei modelli LLMs}{12}{subsection.2.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Confronto tra i diversi modelli di linguaggio \cite  {yao2024survey}\relax }}{12}{table.caption.14}\protected@file@percent }
\newlabel{LLMs}{{2.1}{12}{Confronto tra i diversi modelli di linguaggio \cite {yao2024survey}\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Generative Pre-trained Transformer (GPT)}{12}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{GPT-4 Performance}{12}{section*.15}\protected@file@percent }
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{chen2021evaluating}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\newlabel{equ:scaling}{{2.1}{13}{GPT-4 Performance}{equation.2.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  Performance di GPT-4 e modelli più piccoli. La metrica è la perdita finale su un dataset interno, la linea tratteggiata corrisponde alle legge adattata ai modelli più piccoli, predicendo con precisione la perdita finale di GPT-4. L'asse x rappresenta il calcolo di addestramento normalizzato in modo che GPT-4 sia uguale a 1 \cite  {achiam2023gpt}.\relax }}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:loss-prediction}{{2.1}{13}{Performance di GPT-4 e modelli più piccoli. La metrica è la perdita finale su un dataset interno, la linea tratteggiata corrisponde alle legge adattata ai modelli più piccoli, predicendo con precisione la perdita finale di GPT-4. L'asse x rappresenta il calcolo di addestramento normalizzato in modo che GPT-4 sia uguale a 1 \cite {achiam2023gpt}.\relax }{figure.caption.16}{}}
\newlabel{equ:power_law}{{2.2}{13}{GPT-4 Performance}{equation.2.2.2}{}}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  Performance di GPT-4 e modelli più piccoli. La metrica è la media del logaritmo del tasso di successo su un sottoinsieme di HumanEval. L'asse x rappresenta il calcolo di addestramento normalizzato in modo che GPT-4 sia pari a 1 \cite  {achiam2023gpt}.\relax }}{14}{figure.caption.17}\protected@file@percent }
\newlabel{fig:pass-rate}{{2.2}{14}{Performance di GPT-4 e modelli più piccoli. La metrica è la media del logaritmo del tasso di successo su un sottoinsieme di HumanEval. L'asse x rappresenta il calcolo di addestramento normalizzato in modo che GPT-4 sia pari a 1 \cite {achiam2023gpt}.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  performance di GPT-4 su esami accademici e professionali, simulando le condizioni e il sistema di valutazione degli esami reali \cite  {achiam2023gpt}.\relax }}{14}{figure.caption.18}\protected@file@percent }
\newlabel{fig:exam-results}{{2.3}{14}{performance di GPT-4 su esami accademici e professionali, simulando le condizioni e il sistema di valutazione degli esami reali \cite {achiam2023gpt}.\relax }{figure.caption.18}{}}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{achiam2023gpt}
\citation{masalkhi2024google}
\citation{waisberg2023bridging}
\citation{kocon2023chatgpt}
\citation{jeyaraman2023chatgpt}
\citation{waisberg2023chatgpt}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  prestazioni di GPT-4 su benchmarks accademici \cite  {achiam2023gpt}.\relax }}{15}{figure.caption.19}\protected@file@percent }
\newlabel{fig:GPT4-benchmarks}{{2.4}{15}{prestazioni di GPT-4 su benchmarks accademici \cite {achiam2023gpt}.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  prestazioni di GPT-4 sui MMLU benchmarks tradotti in altre lingue in confronto ad altri modelli \cite  {achiam2023gpt}.\relax }}{15}{figure.caption.20}\protected@file@percent }
\newlabel{fig:GPT4-languages-benchmarks}{{2.5}{15}{prestazioni di GPT-4 sui MMLU benchmarks tradotti in altre lingue in confronto ad altri modelli \cite {achiam2023gpt}.\relax }{figure.caption.20}{}}
\citation{chen2023fiction}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Google Gemini}{16}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Impatti e Applicazioni degli LLMs}{16}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Applicazioni nel business e nella finanza}{16}{subsection.2.3.1}\protected@file@percent }
\citation{chen2023fiction}
\citation{chen2023fiction}
\citation{zheng2024large}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces  Valori di ritorno per ogni categoria del sentiment negativo generato da GPT-3.5 E GPT-4 \cite  {chen2023fiction}.\relax }}{17}{figure.caption.21}\protected@file@percent }
\newlabel{fig:sentiment-analysis}{{2.6}{17}{Valori di ritorno per ogni categoria del sentiment negativo generato da GPT-3.5 E GPT-4 \cite {chen2023fiction}.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Applicazioni e benefici nella medicina}{17}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Capacità di diagnosi e previsione migliorate}{17}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Integrazione della conoscenza e accesso in tempo reale}{17}{section*.23}\protected@file@percent }
\citation{huang2023chatgpt}
\citation{d2024large}
\citation{wang2023huatuo}
\citation{singhal2023large}
\citation{chakraborty2023artificial}
\citation{omiye2024large}
\citation{puladi2023impact}
\citation{grunebaum2023exciting}
\citation{schwartz2024black}
\citation{feldman2019development}
\citation{biswas2023role}
\citation{luo2022biogpt}
\citation{lee2020biobert}
\citation{zheng2024large}
\citation{zheng2024large}
\citation{zheng2024large}
\citation{kraljevic2021medgpt}
\citation{shi2023llm}
\citation{zhou2023skingpt}
\citation{xiong2023doctorglm}
\citation{wang2023huatuo}
\citation{wang2023clinicalgpt}
\citation{lin2022pangu}
\citation{fang2023method}
\citation{mao2023transformer}
\citation{luo2023towards}
\citation{zhu2021dsi}
\citation{lei2023medlsam}
\citation{li2023lvit}
\citation{koleilat2024medclip}
\citation{li2023chatdoctor}
\citation{bao2023disc}
\citation{chen2023bianque}
\citation{qiu2023smile}
\citation{wu2024pmc}
\citation{liu2023medical}
\citation{he2024pefomed}
\citation{wang2021cloud}
\citation{yang2022large}
\citation{zheng2024large}
\citation{zheng2024large}
\@writefile{toc}{\contentsline {subsubsection}{Trattamenti personalizzati e sviluppo di farmaci}{18}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Gestione dei pazienti e ottimizzazione dei processi sanitari}{18}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Educazione clinica e diffusione della conoscenza medica}{18}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Applicazioni e Supporto degli LLM in Diverse Specialità Mediche}{18}{section*.27}\protected@file@percent }
\citation{10198233}
\citation{10198233}
\citation{10198233}
\citation{calbimonte2023powershell}
\citation{calbimonte2023powershell}
\citation{calbimonte2023powershell}
\citation{calbimonte2023powershell}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces  I punti critici delle cure mediche e le applicazioni dei LLM medici \cite  {zheng2024large}.\relax }}{19}{figure.caption.28}\protected@file@percent }
\newlabel{fig:llms-medicine}{{2.7}{19}{I punti critici delle cure mediche e le applicazioni dei LLM medici \cite {zheng2024large}.\relax }{figure.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Informazioni sui diversi LLMs medici e il loro campo di applicazione \cite  {zheng2024large}.\relax }}{19}{table.caption.29}\protected@file@percent }
\newlabel{tab:medical-LLMs}{{2.2}{19}{Informazioni sui diversi LLMs medici e il loro campo di applicazione \cite {zheng2024large}.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Impatti nella Cybersecurity}{19}{subsection.2.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces  Riepilogo dell'impatto degli LLMs nella Cybersecurity e strategie future \cite  {10198233}.\relax }}{19}{figure.caption.30}\protected@file@percent }
\newlabel{fig:cybersecurity-impact}{{2.8}{19}{Riepilogo dell'impatto degli LLMs nella Cybersecurity e strategie future \cite {10198233}.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{LLMs per la Cyber Defense}{19}{section*.31}\protected@file@percent }
\citation{calbimonte2023powershell}
\citation{calbimonte2023powershell}
\citation{10198233}
\citation{10198233}
\newlabel{fig:logs-detecting}{{2.9a}{20}{ChatGPT individua problemi di sicurezza nei log di accesso \cite {calbimonte2023powershell}.\relax }{figure.caption.32}{}}
\newlabel{sub@fig:logs-detecting}{{a}{20}{ChatGPT individua problemi di sicurezza nei log di accesso \cite {calbimonte2023powershell}.\relax }{figure.caption.32}{}}
\newlabel{fig:cpu-consuming}{{2.9b}{20}{PowerShell script che individua quale tabella in AdventureWorks2019 database consuma più cpu \cite {calbimonte2023powershell}.\relax }{figure.caption.32}{}}
\newlabel{sub@fig:cpu-consuming}{{b}{20}{PowerShell script che individua quale tabella in AdventureWorks2019 database consuma più cpu \cite {calbimonte2023powershell}.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces \relax }}{20}{figure.caption.32}\protected@file@percent }
\citation{10198233}
\citation{10198233}
\citation{10198233}
\citation{10198233}
\citation{10198233}
\citation{10198233}
\citation{10198233}
\citation{10198233}
\@writefile{toc}{\contentsline {subsubsection}{LLMs per la Cyber Offense}{21}{section*.33}\protected@file@percent }
\newlabel{cyber-offense}{{2.3.3}{21}{LLMs per la Cyber Offense}{section*.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces \relax }}{21}{figure.caption.34}\protected@file@percent }
\newlabel{fig:pishing-social_engineering}{{2.10}{21}{\relax }{figure.caption.34}{}}
\citation{10198233}
\citation{yao2024survey}
\citation{talat2022you}
\citation{urchs2023prevalent}
\citation{dong2023probing}
\citation{kotek2023gender}
\citation{felkner2023winoqueer}
\citation{shaikh2022second}
\citation{urman2023silence}
\citation{su2023fake}
\citation{wan2023kelly}
\citation{fang2024bias}
\citation{poremba2023chatgpt}
\citation{maddison2023samsung}
\citation{burgess2023chatgpt}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Generazione di payload SQL injections utilizzando ChatGPT DAN jailbreak \cite  {10198233}.\relax }}{22}{figure.caption.35}\protected@file@percent }
\newlabel{fig:SQL-injections}{{2.11}{22}{Generazione di payload SQL injections utilizzando ChatGPT DAN jailbreak \cite {10198233}.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Implicazioni sociali, etiche e legali degli LLMs}{22}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Implicazioni Etiche e Sociali dei Bias nei Modelli di Linguaggio}{22}{subsection.2.4.1}\protected@file@percent }
\citation{achiam2023gpt}
\citation{10198233}
\citation{DBLP:journals/corr/abs-1907-07844}
\citation{hinton2006reducing}
\citation{zeiler2014visualizing}
\citation{girshick2014rich}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Sicurezza dei Dati e Privacy: Incidenti e Rischi Associati ai Modelli di Linguaggio}{23}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Disinformazione ed Allucinazioni nei Modelli di Linguaggio: Rischi di Diffusione di Informazioni Errate}{23}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Tecniche di generazione e miglioramento}{23}{section.2.5}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1907-07844}
\citation{krizhevsky2017imagenet}
\citation{russakovsky2015imagenet}
\citation{xiao2016sun}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Fine-Tuning}{24}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reti neurali sviluppative}{24}{section*.36}\protected@file@percent }
\citation{pu2023empiricalanalysisstrengthsweaknesses}
\citation{mao2021unipelt}
\citation{pu2023empiricalanalysisstrengthsweaknesses}
\citation{chung2024scaling}
\citation{zhang2015character}
\citation{warstadt2019neural}
\citation{novikova2017e2e}
\citation{gliwa2019samsum}
\citation{pu2023empiricalanalysisstrengthsweaknesses}
\citation{pu2023empiricalanalysisstrengthsweaknesses}
\citation{pu2023empiricalanalysisstrengthsweaknesses}
\citation{pu2023empiricalanalysisstrengthsweaknesses}
\@writefile{toc}{\contentsline {subsubsection}{Parameter Efficent Fine-Tuning}{25}{section*.37}\protected@file@percent }
\citation{cuconasu2024power}
\citation{salton1983introduction}
\citation{cuconasu2024power}
\citation{karpukhin2020dense}
\citation{lewis2020retrieval}
\citation{mialon2023augmented}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Confronto tra diverse tecniche di PEFT in termini di tempo totale di esecuzione degli esperimenti, normalizzato rispetto al tempo totale di addestramento completo del modello \cite  {pu2023empiricalanalysisstrengthsweaknesses}.\relax }}{27}{figure.caption.38}\protected@file@percent }
\newlabel{fig:resources-scaling}{{2.12}{27}{Confronto tra diverse tecniche di PEFT in termini di tempo totale di esecuzione degli esperimenti, normalizzato rispetto al tempo totale di addestramento completo del modello \cite {pu2023empiricalanalysisstrengthsweaknesses}.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces  Il benchmarking del modello FLAN-T5 è stato effettuato su diversi set di dati. Per AG News e CoLA, è stata misurata l'accuratezza basata su una corrispondenza esatta delle stringhe, mentre per E2E Dataset e SAMSum si è stimato il ROUGE-L, che misura la lunghezza della sottosequenza comune più lunga, con valori più alti che indicano prestazioni migliori \cite  {pu2023empiricalanalysisstrengthsweaknesses}.\relax }}{27}{figure.caption.39}\protected@file@percent }
\newlabel{fig:PEFT-benchmarks}{{2.13}{27}{Il benchmarking del modello FLAN-T5 è stato effettuato su diversi set di dati. Per AG News e CoLA, è stata misurata l'accuratezza basata su una corrispondenza esatta delle stringhe, mentre per E2E Dataset e SAMSum si è stimato il ROUGE-L, che misura la lunghezza della sottosequenza comune più lunga, con valori più alti che indicano prestazioni migliori \cite {pu2023empiricalanalysisstrengthsweaknesses}.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Retrieval Augmented Generation (RAG)}{27}{subsection.2.5.2}\protected@file@percent }
\citation{databricks2024rag}
\citation{databricks2024rag}
\citation{databricks2024rag}
\@writefile{toc}{\contentsline {subsubsection}{RAG ed LLMs}{28}{section*.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces  Prototipo di architettura RAG e flusso di lavoro \cite  {databricks2024rag}.\relax }}{28}{figure.caption.41}\protected@file@percent }
\newlabel{fig:RAG-architecture}{{2.14}{28}{Prototipo di architettura RAG e flusso di lavoro \cite {databricks2024rag}.\relax }{figure.caption.41}{}}
\@setckpt{capitoli/capitolo2}{
\setcounter{page}{29}
\setcounter{equation}{2}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{6}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{5}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{14}
\setcounter{table}{2}
\setcounter{Item}{0}
\setcounter{Hfootnote}{6}
\setcounter{bookmark@seq@number}{28}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{lstnumber}{1}
\setcounter{float@type}{16}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{parentequation}{0}
\setcounter{thm}{0}
\setcounter{defn}{0}
\setcounter{example}{0}
\setcounter{oss}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{blindtext}{1}
\setcounter{Blindtext}{5}
\setcounter{blind@countparstart}{0}
\setcounter{blindlist}{0}
\setcounter{blindlistlevel}{0}
\setcounter{blindlist@level}{0}
\setcounter{blind@listcount}{0}
\setcounter{blind@levelcount}{0}
\setcounter{blind@randomcount}{0}
\setcounter{blind@randommax}{0}
\setcounter{blind@pangramcount}{0}
\setcounter{blind@pangrammax}{0}
\setcounter{section@level}{3}
\setcounter{lstlisting}{0}
}
